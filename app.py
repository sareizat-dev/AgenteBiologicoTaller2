import streamlit as st
from langchain_groq import ChatGroq
from langchain.memory import ConversationBufferMemory
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

# ConfiguraciÃ³n de la pÃ¡gina
st.set_page_config(page_title="ğŸ§¬ Agente de BiologÃ­a", page_icon="ğŸ§¬", layout="wide")

# Estilos CSS personalizados
st.markdown(
    """
    <style>
    body {
        background-color: #f0fff4;
    }
    .stTextInput > div > div > input {
        border: 2px solid #2f855a;
        border-radius: 10px;
    }
    .stButton button {
        background-color: #38a169;
        color: white;
        border-radius: 10px;
        font-weight: bold;
    }
    .stButton button:hover {
        background-color: #2f855a;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# TÃ­tulo
st.title("ğŸ§¬ Agente Virtual de BiologÃ­a")
st.write("Este asistente responde **Ãºnicamente preguntas de biologÃ­a**. "
         "Puede ayudarte a entender conceptos, identificar especies por descripciÃ³n "
         "y explicar procesos biolÃ³gicos complejos.")

# Entrada de API Key
api_key = st.text_input("ğŸ”‘ Ingresa tu API Key de Groq:", type="password")

if api_key:
    # Prompt especializado en biologÃ­a (incluye history para compatibilidad)
    prompt_template = """
    Eres un experto en biologÃ­a. Usa el historial de conversaciÃ³n para mantener coherencia.
    Responde de forma clara, educativa y detallada **Ãºnicamente a preguntas de biologÃ­a**. 

    Si la pregunta no estÃ¡ relacionada con biologÃ­a, responde estrictamente:
    "Lo siento, solo puedo responder preguntas sobre biologÃ­a."

    Historial de conversaciÃ³n:
    {history}

    Pregunta actual: {input}
    Respuesta:
    """
    PROMPT = PromptTemplate(
        template=prompt_template,
        input_variables=["history", "input"]
    )

    # Inicializar el modelo Llama3 Groq
    llm = ChatGroq(
        groq_api_key=api_key,
        model_name="llama3-8b-8192",
        temperature=0.3,
        max_tokens=512,
    )

    # Manejo de memoria y conversaciÃ³n
    if "memory" not in st.session_state:
        st.session_state.memory = ConversationBufferMemory(
            memory_key="history", return_messages=False
        )
    if "conversation" not in st.session_state:
        st.session_state.conversation = LLMChain(
            llm=llm,
            prompt=PROMPT,
            memory=st.session_state.memory,
            verbose=False
        )
    if "history_ui" not in st.session_state:
        st.session_state.history_ui = []

    # Layout para entrada de usuario
    col1, col2, col3 = st.columns([4, 1, 1])
    with col1:
        user_input = st.text_input("ğŸ’¬ Haz una pregunta sobre biologÃ­a:", key="input_box")
    with col2:
        if st.button("ğŸ§¹ Limpiar caja"):
            st.session_state.input_box = ""
    with col3:
        if st.button("ğŸ—‘ï¸ Borrar historial"):
            st.session_state.history_ui = []
            st.session_state.memory.clear()

    # Procesar pregunta
    if st.button("Enviar", type="primary"):
        if user_input.strip():
            with st.spinner("ğŸ§¬ Analizando tu pregunta..."):
                response = st.session_state.conversation.run(input=user_input)
            st.session_state.history_ui.append(
                {"pregunta": user_input, "respuesta": response}
            )
            st.session_state.input_box = ""
        else:
            st.warning("âš ï¸ Escribe una pregunta antes de enviar.")

    # Mostrar historial
    st.subheader("ğŸ“œ Historial de conversaciÃ³n")
    for chat in st.session_state.history_ui:
        st.markdown(f"**ğŸ‘¤ Usuario:** {chat['pregunta']}")
        st.markdown(f"**ğŸ§¬ Agente:** {chat['respuesta']}")
else:
    st.info("ğŸ”‘ Ingresa tu API Key de Groq para comenzar.")

# Footer
st.caption("ğŸŒ± Powered by LangChain + Groq + Llama3-8B-8192")
